# Tristan Kruse


### About Me

- üéì **Education:**  
  - Master's in Business Analytics & Operations Research (Supply Chain Management), Catholic University of Eichst√§tt-Ingolstadt.  
  - Bachelor's in Business Management (Supply Chain Management), Bonn-Rhein-Sieg University of Applied Sciences.

- üíº **Work Experience:**  
  - Data Analyst at Genpact, specializing in supply chain analytics, dashboard development, and data optimization.  

- üåê **Connect:**  
  - [LinkedIn](https://www.linkedin.com/in/tristan-kruse)  
  - üìß [krusetristan1@gmail.com](mailto:krusetristan1@gmail.com)

- üìñ **Interests:**
  - Beyond my passion for data, I enjoy playing chess, reading, listening to podcasts, exploring mathematics, learning new languages, and practicing martial arts.


### Welcome to My GitHub! üåü

Welcome to my GitHub! I'm Tristan Kruse, a passionate professional with a strong focus on **Supply Chain Management** and **Data Analytics**, I'm deeply interested in leveraging technology to solve complex supply chain challenges.

üíª My work involves tools and technologies like Python, SQL, AWS, and Tableau, with applications in reinforcement learning, forecasting, and decision optimization.

üåü Highlights:
- Data Analyst at Genpact, developing dashboards and optimizing data workflows to enhance supply chain operations.
- Modeled and solved complex supply chain problems, including the Beer Game, using Reinforcement Learning.
- Worked on innovative projects like EnginBERT for engineering literature retrieval and a returns optimization model using Neural Networks.

Thanks for visiting!





## üî¨ Featured Projects

### Reinforcement Learning Assignment Algorithm (RL-ACA)
A reinforcement learning approach to optimize food delivery logistics, addressing the Restaurant Meal Delivery Problem through an enhanced Anticipatory Customer
Assignment framework. The project introduces RL-ACA, a novel algorithm that uses dynamic postponement strategies learned through Deep Q-Networks to optimize
delivery assignment and bundling decisions. The system is comprehensively validated using real-world Meituan data (647,395 orders across 22 districts) and
features statistical analysis across multiple operational contexts.

**Repo**: [RMDP_Algorithm](https://github.com/TristanKruse/RMDP_Algorithm) 
**Technologies**: Python, PyTorch (Deep Q-Network), NumPy, Pandas, Statistical Analysis, Real-time

**Highlights**:
- Achieves a 5.5% reduction in average distance per order and 1.5 percentage point lower idle rates through intelligent postponement decisions, improving driver
efficiency and platform sustainability.
- Demonstrates superior performance in high-stress scenarios with 4.4 percentage point advantage in on-time delivery rates, showcasing adaptability under
operational pressure.
- Validates performance across 120 real-world scenarios with statistical significance testing, providing robust evidence of algorithm effectiveness in diverse
urban delivery contexts.
- Features comprehensive benchmarking framework comparing RL-ACA against baseline methods, with detailed analysis of trade-offs between routing efficiency and
delivery timeliness across stakeholder priorities.

### OmniChannel-RL
A reinforcement learning framework for modeling returns and decision-making in omnichannel retail. The project leverages a Hierarchical Markov Decision Process (HMDP) and the Proximal Policy Optimization (PPO) algorithm to optimize ordering and allocation strategies for retailers operating online and offline channels with resellable returns.

Repo: [OmniChannel-RL](https://github.com/TristanKruse/Modelling_returns_omni-channel_retail_Reinforcement_Learning)
Technologies: Python, TensorFlow, Keras, NumPy, Gym
Highlights: Achieved a 3% reduction in total costs and up to a 17% increase in service levels. The model is based on the framework outlined in the paper J. Goedhart, R. Haijema, and R. Akkerman (2023), showcasing the potential of reinforcement learning in complex, hierarchical decision-making environments.

### Beer-Game-RL
A reinforcement learning solution for the Supply Chain Beer Game. Modeled the game's supply chain dynamics in Python (NumPy, Pandas) and implemented Q-Learning to optimize ordering strategies. Achieved a 31% reduction in total costs by modifying the state space, demonstrating the potential of RL in supply chain optimization.

Repo: [Beer-Game-RL](https://github.com/TristanKruse/Beer-Game-RL)
Technologies: Python, NumPy, Pandas, Q-Learning
Highlights: Combines supply chain simulation with reinforcement learning to explore automated decision-making and cost minimization in complex systems.


## üõ†Ô∏è Languages and Tools:

**Languages**

<a href="https://www.python.org" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/python/python-original.svg" alt="python" width="40" height="40"/> </a>
<a href="https://www.w3schools.com/sql/" target="_blank" rel="noreferrer"> <img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQviJKGbz-VEIvrZlwSpJaIAJC3w35lFP4TzIdVG_eMTQ&s" alt="SQL" width="40" height="40"/> </a>
<a href="https://www.r-project.org" target="_blank" rel="noreferrer"> <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/R_logo.svg/1200px-R_logo.svg.png" alt="R" width="40" height="40"/> </a>

**Visualization**

<a href="https://www.tableau.com" target="_blank" rel="noreferrer"> <img src="https://github.com/gilbarbara/logos/blob/main/logos/tableau-icon.svg" alt="tableau" width="40" height="40"/> </a> 
<a href="https://aws.amazon.com/quicksight/" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/tandpfun/skill-icons/main/icons/AWS-Light.svg" alt="quicksight" width="40" height="40"/> </a>

